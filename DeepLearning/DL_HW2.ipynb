{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_HW2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1pfkA8WGG1W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.datasets import reuters\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8igMKjhGQuK",
        "colab_type": "code",
        "outputId": "b068f85a-591c-40de-97f0-fc1543281346",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=None, test_split=0.2)\n",
        "print(f'# of Training Samples: {len(x_train)}')\n",
        "print(f'# of Test Samples: {len(x_test)}')\n",
        "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# of Training Samples: 8982\n",
            "# of Test Samples: 2246\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZTNfGn9Gyhz",
        "colab_type": "code",
        "outputId": "b5387249-291a-478b-ac30-5203c0760fbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "num_classes = max(y_train) + 1\n",
        "print('# of Classes: {}'.format(num_classes))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# of Classes: 46\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7KmtAMnG05l",
        "colab_type": "code",
        "outputId": "53266b37-f133-40e1-af3b-a8d49855e98c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "index_to_word = {}\n",
        "for key, value in word_index.items():\n",
        "    index_to_word[value] = key\n",
        "print(' '.join([index_to_word[x] for x in x_train[1]]))\n",
        "print(y_train[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the termination payment airport takes 6 visibility geological 3 6 602 begin up said fully bank expects commodity total is giant a recreation this takes leroy series termination payment airport mln a for capital 1 pre 50 american east said in council takes leroy recommend's france a but u any 4 s 1st losses pct dlrs\n",
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ptcvVkWHLoN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziY2WplrH-mQ",
        "colab_type": "code",
        "outputId": "af146bad-3d1c-40f3-8f62-1c3835b6d3b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "max_words = 10000\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "x_train = tokenizer.sequences_to_matrix(x_train, mode='binary')\n",
        "x_test = tokenizer.sequences_to_matrix(x_test, mode='binary')\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "print(x_train[0])\n",
        "print(len(x_train[0]))\n",
        "\n",
        "print(y_train[0])\n",
        "print(len(y_train[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 1. 0. ... 0. 0. 0.]\n",
            "10000\n",
            "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "46\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0klOlq0IB-6",
        "colab_type": "code",
        "outputId": "38b018ff-e682-4028-d62a-7780527ceeab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "\n",
        "print('Building model...')\n",
        "batch_size = 32\n",
        "epochs = 4\n",
        "model = Sequential()\n",
        "model.add(Dense(512, input_shape=(max_words,)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1)\n",
        "score = model.evaluate(x_test, y_test,\n",
        "                       batch_size=batch_size, verbose=1)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building model...\n",
            "Train on 8083 samples, validate on 899 samples\n",
            "Epoch 1/4\n",
            "8083/8083 [==============================] - 29s 4ms/step - loss: 1.2966 - acc: 0.7231 - val_loss: 0.9637 - val_acc: 0.7953\n",
            "Epoch 2/4\n",
            "8083/8083 [==============================] - 28s 3ms/step - loss: 0.4909 - acc: 0.8894 - val_loss: 0.8991 - val_acc: 0.8053\n",
            "Epoch 3/4\n",
            "8083/8083 [==============================] - 27s 3ms/step - loss: 0.2779 - acc: 0.9374 - val_loss: 0.9159 - val_acc: 0.8131\n",
            "Epoch 4/4\n",
            "8083/8083 [==============================] - 28s 3ms/step - loss: 0.2227 - acc: 0.9501 - val_loss: 0.9472 - val_acc: 0.7998\n",
            "2246/2246 [==============================] - 1s 399us/step\n",
            "Test score: 0.9128817384623038\n",
            "Test accuracy: 0.8081032947992918\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_Uu1ewIYPog",
        "colab_type": "code",
        "outputId": "3c64cfa9-11e2-46f4-e452-cf7b2314f81f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "print('Building model...')\n",
        "batch_size = 32\n",
        "epochs = 4\n",
        "model = Sequential()\n",
        "model.add(Dense(512, input_shape=(max_words,)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(4))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1)\n",
        "score = model.evaluate(x_test, y_test,\n",
        "                       batch_size=batch_size, verbose=1)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building model...\n",
            "Train on 8083 samples, validate on 899 samples\n",
            "Epoch 1/4\n",
            "8083/8083 [==============================] - 31s 4ms/step - loss: 2.7784 - acc: 0.0700 - val_loss: 2.3203 - val_acc: 0.0745\n",
            "Epoch 2/4\n",
            "8083/8083 [==============================] - 30s 4ms/step - loss: 1.7702 - acc: 0.2410 - val_loss: 1.4955 - val_acc: 0.6085\n",
            "Epoch 3/4\n",
            "8083/8083 [==============================] - 30s 4ms/step - loss: 0.9870 - acc: 0.6770 - val_loss: 1.4852 - val_acc: 0.6863\n",
            "Epoch 4/4\n",
            "8083/8083 [==============================] - 30s 4ms/step - loss: nan - acc: 0.5922 - val_loss: nan - val_acc: 0.0033\n",
            "2246/2246 [==============================] - 1s 413us/step\n",
            "Test score: nan\n",
            "Test accuracy: 0.005342831700801425\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnzo-VRb91xJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}